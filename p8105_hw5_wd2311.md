p8105_hw5_wd2311
================
wd2311
2025-11-14

## Loading package

``` r
library(tidyverse)
```

    ## â”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 2.0.0 â”€â”€
    ## âœ” dplyr     1.1.4     âœ” readr     2.1.5
    ## âœ” forcats   1.0.0     âœ” stringr   1.5.2
    ## âœ” ggplot2   4.0.0     âœ” tibble    3.3.0
    ## âœ” lubridate 1.9.4     âœ” tidyr     1.3.1
    ## âœ” purrr     1.1.0     
    ## â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€
    ## âœ– dplyr::filter() masks stats::filter()
    ## âœ– dplyr::lag()    masks stats::lag()
    ## â„¹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(rvest)
```

    ## 
    ## Attaching package: 'rvest'
    ## 
    ## The following object is masked from 'package:readr':
    ## 
    ##     guess_encoding

## Figures settings

``` r
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

# Problem 1

## Define birthday-checking function

``` r
bday_sim = function(n_room) {
  birthdays = sample(1:365, n_room, replace = TRUE)
repeated_bday = length(unique(birthdays)) < n_room
repeated_bday
}

bday_sim(20)
```

    ## [1] FALSE

## 10000 simulation runs

``` r
bday_sim_results = 
  expand_grid(
    bdays = 2:50,
    iter = 1:10000
  ) |> 
  mutate(
    result = map_lgl(bdays, bday_sim)
  ) |> 
  group_by(bdays) |> 
  summarize(
    prob_repeat = mean(result)
  )
```

## Plot the function

``` r
bday_sim_results |> 
  ggplot(aes(x = bdays, y = prob_repeat)) +
  geom_point() +
  geom_line() +
  labs(
    x = "Group Size", 
    y = "Probability",
    title = "Probability of Sharing Birthday for Increasing Group Size"
  )
```

<img src="p8105_hw5_wd2311_files/figure-gfm/unnamed-chunk-5-1.png" width="90%" />

The probability is very small for small groups, but it rises quickly as
group size increases. Around 23 people, the probability is already about
0.5â€”thereâ€™s roughly a 50% chance that at least two people share a
birthday.By about 40â€“50 people, the probability is above 90%,
approaching 1 as the group grows. This is the classic birthday paradox.
Even though there are 365 possible birthdays, we donâ€™t need anything
close to 365 people before a match becomes very likely. The curveâ€™s
steep, nonlinear rise shows how quickly shared birthdays become almost
guaranteed as the group size increases.

## Problem 2

## Set ğœ‡=0 and Generate 5000 datasets from the model

``` r
powermu_zero = 
  expand_grid(
    sample_n = 30,
    sample_sd = 5,
    mu = 0,
    iter = 1:5000
  ) |> 
  mutate(data = map(iter, ~rnorm(sample_n, mean = mu, sd = sample_sd))) |> 
  mutate(tidy = map(data, ~broom::tidy(t.test(.x, mu = 0)))) |> 
  mutate(mu_hat = map_dbl(tidy, "estimate"),
         p_value = map_dbl(tidy, "p.value"))
```

## Repeat the above for ğœ‡={1,2,3,4,5,6}

``` r
power_sim = 
  expand_grid(
    mu = 1:6, 
    iter = 1:5000) |> 
  mutate(
    data = map(mu, ~ rnorm(n = 30, mean = .x, sd = 5)),
    ttest = map(data, ~broom::tidy(t.test(.x, mu = 0)))
    
  ) |> 
  unnest(ttest) |> 
  select(mu, iter, estimate, p.value)
```

## Describe the association between effect size and power.

``` r
power_sim |> 
  group_by(mu) |> 
  summarize(
    power = mean(p.value < 0.05)
  ) |> 
  ggplot(aes(x = mu, y = power)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(
  x = "True Value of Î¼",
  y = "Power (Proportion Null Rejected)",
  title = "Power and the True Value of Î¼"
)
```

    ## `geom_smooth()` using method = 'loess' and formula = 'y ~ x'

<img src="p8105_hw5_wd2311_files/figure-gfm/unnamed-chunk-8-1.png" width="90%" />

As the true value of Î¼ increases, the power of the one-sample t-test
increases sharply. When Î¼ is near zero, the probability of rejecting the
null hypothesis is near the nominal Î± = 0.05. As Î¼ grows from 1 to 3,
the test becomes increasingly sensitive and power rises rapidly. For Î¼ â‰¥
4, power approaches 1, meaning the test almost always detects the
effect. This demonstrates that larger effect sizes lead to higher power,
given fixed sample size and variance.

## Average Estimates of Î¼ vs.Â True Î¼

``` r
power_sim |> 
  group_by(mu) |> 
  summarize(
    avg_est = mean(estimate),
    avg_est_rejectnull = mean(estimate[p.value < 0.05], na.rm = TRUE)
  ) |> 
  pivot_longer(cols = c(avg_est, avg_est_rejectnull),
               names_to = "type",
               values_to = "value") |> 
  ggplot(aes(x = mu, y = value, color = type)) +
  geom_line() +
  geom_point() +
  scale_color_viridis_d(labels = c("All Estimates", "Estimates (Null Rejected)")) +
  labs(
    x = "True Value of Î¼",
    y = "Average Estimate of Î¼",
    color = "Estimate Type",
    title = "Average Estimates of Î¼ vs. True Î¼"
  )
```

<img src="p8105_hw5_wd2311_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />

The average Î¼Ì‚ among samples where the null is rejected is not equal to
the true Î¼, especially when Î¼ is small.This is because restricting to
significant tests selects only the samples in which random noise pushed
Î¼Ì‚ upward enough to pass the significance threshold. This creates upward
bias in the estimate, known as the â€œwinnerâ€™s curseâ€ or significance
filter bias. Only when Î¼ is large and power is high do the two averages
converge and become approximately equal.
