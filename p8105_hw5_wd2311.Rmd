---
title: "p8105_hw5_wd2311"
author: "wd2311"
date: "2025-11-14"
output: github_document
---
## Loading package
```{r}
library(tidyverse)
library(rvest)
```

## Figures settings
```{r}
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```


# Problem 1

## Define birthday-checking function
```{r}
bday_sim = function(n_room) {
  birthdays = sample(1:365, n_room, replace = TRUE)
repeated_bday = length(unique(birthdays)) < n_room
repeated_bday
}

bday_sim(20)
```

## 10000 simulation runs
```{r}
bday_sim_results = 
  expand_grid(
    bdays = 2:50,
    iter = 1:10000
  ) |> 
  mutate(
    result = map_lgl(bdays, bday_sim)
  ) |> 
  group_by(bdays) |> 
  summarize(
    prob_repeat = mean(result)
  )
```

## Plot the function
```{r}
bday_sim_results |> 
  ggplot(aes(x = bdays, y = prob_repeat)) +
  geom_point() +
  geom_line() +
  labs(
    x = "Group Size", 
    y = "Probability",
    title = "Probability of Sharing Birthday for Increasing Group Size"
  )
```

The probability is very small for small groups, but it rises quickly as group size increases.
Around 23 people, the probability is already about 0.5‚Äîthere‚Äôs roughly a 50% chance that at least two people share a birthday.By about 40‚Äì50 people, the probability is above 90%, approaching 1 as the group grows.
This is the classic birthday paradox. Even though there are 365 possible birthdays, we don‚Äôt need anything close to 365 people before a match becomes very likely. The curve‚Äôs steep, nonlinear rise shows how quickly shared birthdays become almost guaranteed as the group size increases.


## Problem 2

## Set ùúá=0 and Generate 5000 datasets from the model
```{r}
powermu_zero = 
  expand_grid(
    sample_n = 30,
    sample_sd = 5,
    mu = 0,
    iter = 1:5000
  ) |> 
  mutate(data = map(iter, ~rnorm(sample_n, mean = mu, sd = sample_sd))) |> 
  mutate(tidy = map(data, ~broom::tidy(t.test(.x, mu = 0)))) |> 
  mutate(mu_hat = map_dbl(tidy, "estimate"),
         p_value = map_dbl(tidy, "p.value"))

```


## Repeat the above for ùúá={1,2,3,4,5,6}
```{r}
power_sim = 
  expand_grid(
    mu = 1:6, 
    iter = 1:5000) |> 
  mutate(
    data = map(mu, ~ rnorm(n = 30, mean = .x, sd = 5)),
    ttest = map(data, ~broom::tidy(t.test(.x, mu = 0)))
    
  ) |> 
  unnest(ttest) |> 
  select(mu, iter, estimate, p.value)
  
```

## Describe the association between effect size and power.
```{r}
power_sim |> 
  group_by(mu) |> 
  summarize(
    power = mean(p.value < 0.05)
  ) |> 
  ggplot(aes(x = mu, y = power)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  labs(
  x = "True Value of Œº",
  y = "Power (Proportion Null Rejected)",
  title = "Power and the True Value of Œº"
)
  
```

As the true value of Œº increases, the power of the one-sample t-test increases sharply. When Œº is near zero, the probability of rejecting the null hypothesis is near the nominal Œ± = 0.05. As Œº grows from 1 to 3, the test becomes increasingly sensitive and power rises rapidly. For Œº ‚â• 4, power approaches 1, meaning the test almost always detects the effect. This demonstrates that larger effect sizes lead to higher power, given fixed sample size and variance.


## Average Estimates of Œº vs. True Œº
```{r}
power_sim |> 
  group_by(mu) |> 
  summarize(
    avg_est = mean(estimate),
    avg_est_rejectnull = mean(estimate[p.value < 0.05], na.rm = TRUE)
  ) |> 
  pivot_longer(cols = c(avg_est, avg_est_rejectnull),
               names_to = "type",
               values_to = "value") |> 
  ggplot(aes(x = mu, y = value, color = type)) +
  geom_line() +
  geom_point() +
  scale_color_viridis_d(labels = c("All Estimates", "Estimates (Null Rejected)")) +
  labs(
    x = "True Value of Œº",
    y = "Average Estimate of Œº",
    color = "Estimate Type",
    title = "Average Estimates of Œº vs. True Œº"
  )
```

The average ŒºÃÇ among samples where the null is rejected is not equal to the true Œº,
especially when Œº is small.This is because restricting to significant tests selects 
only the samples in which random noise pushed ŒºÃÇ upward enough to pass the significance
threshold. This creates upward bias in the estimate, known as the ‚Äúwinner‚Äôs curse‚Äù 
or significance filter bias. Only when Œº is large and power is high do the two 
averages converge and become approximately equal.







